{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DCGAN2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1_Y75QXJS6h"
      },
      "source": [
        "### Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHWirlo7FZP7",
        "outputId": "053efa8e-6501-43e3-d98c-6c6d0cb0a6fe"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZKbyU2-AiY-",
        "outputId": "e058063b-acc7-4c69-aac8-8f9a943f40ef"
      },
      "source": [
        "!pip install tensorflow"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (2.3.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.18.5)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.10.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.10.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.12.4)\n",
            "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.4.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.3.3)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.33.2)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.35.1)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.9.2->tensorflow) (50.3.2)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.17.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.7.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (3.3.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (0.4.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.1.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.6)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2020.11.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow) (2.0.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKq-Gc1_EyJk"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wx-zNbLqB4K8"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import time\n",
        "import imageio\n",
        "from keras.optimizers import Adam, SGD\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Reshape\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import Conv2DTranspose\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.layers import Dropout\n",
        "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
        "from numpy.random import randn\n",
        "from numpy.random import randint\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YzTlj4YdCip_",
        "outputId": "46972141-fb33-48a3-a12e-8644c80a753c"
      },
      "source": [
        "# To generate GIFs\n",
        "!pip install gitpython\n",
        "!pip install -q imageio\n",
        "!pip install -q git+https://github.com/tensorflow/docs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gitpython\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/24/d1/a7f8fe3df258549b303415157328bfcc63e9b11d06a7ad7a3327f3d32606/GitPython-3.1.11-py3-none-any.whl (159kB)\n",
            "\r\u001b[K     |██                              | 10kB 23.6MB/s eta 0:00:01\r\u001b[K     |████▏                           | 20kB 20.7MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 30kB 16.2MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 40kB 14.7MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 51kB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 61kB 12.4MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 71kB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 81kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 92kB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 102kB 12.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 112kB 12.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 122kB 12.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 133kB 12.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 143kB 12.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 153kB 12.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 163kB 12.4MB/s \n",
            "\u001b[?25hCollecting gitdb<5,>=4.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/11/d1800bca0a3bae820b84b7d813ad1eff15a48a64caea9c823fc8c1b119e8/gitdb-4.0.5-py3-none-any.whl (63kB)\n",
            "\r\u001b[K     |█████▏                          | 10kB 25.7MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 20kB 32.7MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 30kB 37.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 40kB 40.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 51kB 32.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 61kB 33.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 9.6MB/s \n",
            "\u001b[?25hCollecting smmap<4,>=3.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/b0/9a/4d409a6234eb940e6a78dfdfc66156e7522262f5f2fecca07dc55915952d/smmap-3.0.4-py2.py3-none-any.whl\n",
            "Installing collected packages: smmap, gitdb, gitpython\n",
            "Successfully installed gitdb-4.0.5 gitpython-3.1.11 smmap-3.0.4\n",
            "  Building wheel for tensorflow-docs (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YfIk2es3hJEd",
        "outputId": "69b6c791-9f19-49ae-9a12-9e2239459437"
      },
      "source": [
        "!pip install matplotlib\n",
        "!pip install numpy\n",
        "\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tensorflow.keras import layers\n",
        "from IPython import display\n",
        "import time\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (3.2.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.18.5)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib) (1.15.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.18.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TszVMPeHEyJm"
      },
      "source": [
        "import os\n",
        "import tqdm.notebook as tq\n",
        "from os import listdir\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models\n",
        "import matplotlib.image as mpimg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iP_oD9aiEyJm",
        "outputId": "3593b40c-ff67-4ee3-98d1-5954d685c559"
      },
      "source": [
        "import sys\n",
        "from PIL import Image\n",
        "sys.modules['Image'] = Image \n",
        "\n",
        "from PIL import Image\n",
        "print(Image.__file__)\n",
        "\n",
        "import Image\n",
        "print(Image.__file__)\n",
        "\n",
        "import PIL\n",
        "\n",
        "!pip install sklearn\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/PIL/Image.py\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/Image.py\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn) (0.22.2.post1)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.18.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (0.17.0)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYn4MdZnKCey"
      },
      "source": [
        "### Load and prepare the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpFaCcRwEyJm"
      },
      "source": [
        "from tensorflow.keras.layers import (Dense, \n",
        "                                     BatchNormalization, \n",
        "                                     LeakyReLU, \n",
        "                                     Reshape, \n",
        "                                     Conv2DTranspose,\n",
        "                                     Conv2D,\n",
        "                                     Dropout,\n",
        "                                     Flatten)\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDLry8UqEyJm"
      },
      "source": [
        "#--some helpful stuff for loading images\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.preprocessing.image import load_img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxMzTvCBEyJm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "outputId": "3590e772-dc2f-4860-c945-df40011c2b5f"
      },
      "source": [
        "from PIL import Image\n",
        "from PIL.ImageOps import grayscale\n",
        "trainfolder='/content/drive/MyDrive/ENGS108_Final_Project/Data_Sets/roads_only/'\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "size=(128,128)\n",
        "\n",
        "trainimages=list()\n",
        "for filename in listdir(trainfolder):\n",
        "      if filename!='test126.png':\n",
        "        # load and resize the image\n",
        "        pixels = load_img(trainfolder + filename, target_size=size)\n",
        "        pixels = grayscale(pixels)\n",
        "        # convert to numpy array\n",
        "        pixels = img_to_array(pixels)\n",
        "        # Normalize the images to [-1, 1]\n",
        "        pixels=(pixels- 127.5) / 127.5\n",
        "        # store\n",
        "        trainimages.append(pixels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-716bddc07011>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;34m'test126.png'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# load and resize the image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mpixels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainfolder\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mpixels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrayscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpixels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m# convert to numpy array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/preprocessing/image.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    299\u001b[0m   \"\"\"\n\u001b[1;32m    300\u001b[0m   return image.load_img(path, grayscale=grayscale, color_mode=color_mode,\n\u001b[0;32m--> 301\u001b[0;31m                         target_size=target_size, interpolation=interpolation)\n\u001b[0m\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/utils.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    112\u001b[0m                           'The use of `load_img` requires PIL.')\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcolor_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'grayscale'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0;31m# if image is not already an 8-bit, 16-bit or 32-bit grayscale image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: [Errno 5] Input/output error"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4PIDhoDLbsZ"
      },
      "source": [
        "np_train = np.array(trainimages)\n",
        "BATCH_SIZE = 20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THY-sZMiQ4UV"
      },
      "source": [
        "## Create the models\n",
        "\n",
        "Both the generator and discriminator are defined using the [Keras Sequential API](https://www.tensorflow.org/guide/keras#sequential_model)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dw2tPLmk2pEP"
      },
      "source": [
        "def define_discriminator(in_shape=(128,128,1)):\n",
        "    model = Sequential()\n",
        "    # normal\n",
        "    model.add(Conv2D(128, (5,5), padding='same', input_shape=in_shape))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    # downsample to 64x64\n",
        "    model.add(Conv2D(128, (5,5), strides=(2,2), padding='same'))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    # downsample to 32x32\n",
        "    model.add(Conv2D(128, (5,5), strides=(2,2), padding='same'))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    # downsample to 16x16\n",
        "    model.add(Conv2D(128, (5,5), strides=(2,2), padding='same'))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    # downsample to 8x8\n",
        "    model.add(Conv2D(128, (5,5), strides=(2,2), padding='same'))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    # classifier\n",
        "    model.add(Flatten())\n",
        "    model.add(Dropout(0.1))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    # compile model\n",
        "    opt = SGD(lr=0.0005, momentum = 0.9, nesterov=True)\n",
        "  #  opt = Adam(lr=1e-4, beta_1=0.2)#, beta_1=0.5)\n",
        "    model.compile(loss='mse', optimizer=opt, metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhPneagzCaQv"
      },
      "source": [
        "Use the (as yet untrained) discriminator to classify the generated images as real or fake. The model will be trained to output positive values for real images, and negative values for fake images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDkA05NE6QMs"
      },
      "source": [
        "discriminator = define_discriminator()\n",
        "#decision = discriminator(generated_image)\n",
        "#print (decision)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0FMYgY_mPfTi"
      },
      "source": [
        "## Define the loss and optimizers\n",
        "\n",
        "Define loss functions and optimizers for both models.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psQfmXxYKU3X"
      },
      "source": [
        "# This method returns a helper function to compute cross entropy loss\n",
        "def define_generator(latent_dim=noise_dim):\n",
        "    model = Sequential()\n",
        "    # foundation for 8x8 feature maps\n",
        "    n_nodes = 128 * 8 * 8\n",
        "    model.add(Dense(n_nodes, input_dim=latent_dim))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Reshape((8, 8, 128)))\n",
        "    # upsample to 16x16\n",
        "    model.add(Conv2DTranspose(128, (2,2), strides=(2,2), padding='same'))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    # upsample to 32x32\n",
        "    model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
        "#    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Dropout(0.2))\n",
        "    # upsample to 64x64\n",
        "    model.add(Conv2DTranspose(128, (2,2), strides=(2,2), padding='same'))\n",
        " #   model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    # upsample to 128x128\n",
        "    model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
        "  #  model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    # output layer 128x128x3\n",
        "    model.add(Conv2D(1, (3,3), activation='tanh', padding='same'))\n",
        "    return model\n",
        "\n",
        "def generate_latent_points(latent_dim, n_samples):\n",
        "    # generate points in the latent space\n",
        "    x_input = randn(latent_dim * n_samples)\n",
        "    # reshape into a batch of inputs for the network\n",
        "    x_input = x_input.reshape(n_samples, latent_dim)\n",
        "    return x_input\n",
        "\n",
        "# use the generator to generate n fake examples, with class labels\n",
        "def generate_fake_samples(g_model, latent_dim, n_samples):\n",
        "    # generate points in latent space\n",
        "    x_input = generate_latent_points(latent_dim, n_samples)\n",
        "    # predict outputs\n",
        "    X = g_model.predict(x_input)\n",
        "    # create 'fake' class labels (0)\n",
        "    y = np.zeros((n_samples,1))\n",
        "  #  y = np.random.uniform(0,0.3, n_samples)\n",
        "    return X, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKY_iPSPNWoj"
      },
      "source": [
        "### Discriminator loss\n",
        "\n",
        "This method quantifies how well the discriminator is able to distinguish real images from fakes. It compares the discriminator's predictions on real images to an array of 1s, and the discriminator's predictions on fake (generated) images to an array of 0s."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkMNfBWlT-PV"
      },
      "source": [
        "def define_gan(g_model, d_model):\n",
        "    # make weights in the discriminator not trainable\n",
        "    d_model.trainable = False\n",
        "    # connect them\n",
        "    model = Sequential()\n",
        "    # add generator\n",
        "    model.add(g_model)\n",
        "    # add the discriminator\n",
        "    model.add(d_model)\n",
        "    # compile model\n",
        "    opt = Adam(lr=1e-4, beta_1=0.2)\n",
        "    model.compile(loss='binary_crossentropy', optimizer=opt)\n",
        "    return model\n",
        "\n",
        "# retrive real samples\n",
        "def get_real_samples(dataset, n_samples):\n",
        "    # choose random instances\n",
        "    ix = randint(0, dataset.shape[0], n_samples)\n",
        "    # retrieve selected images\n",
        "    X = dataset[ix]\n",
        "    # set 'real' class labels (1)\n",
        "    y = np.ones((n_samples,1))\n",
        "  #  y = np.random.uniform(0.7,1, n_samples)\n",
        "    return X, y\n",
        "\n",
        "# create and save a plot of generated images\n",
        "def show_generated(generated,epoch, n=5):\n",
        "    #[-1,1] -> [0,1] \n",
        "    #generated = (generated + 1)/ 2\n",
        "    #generated = (generated[:n*n] * 127.5) + 127.5\n",
        "    #generated = generated * 255\n",
        "    plt.figure(figsize=(10,10))\n",
        "    for i in range(2 * n):\n",
        "        plt.subplot(2, n, i + 1)\n",
        "        #img = plt.imread(data_dir + '/' + name)\n",
        "        plt.imshow(generated[i])\n",
        "        #plt.title(name)\n",
        "        plt.axis('off')\n",
        "    plt.savefig('image_at_epoch_{:04d}.png'.format(epoch+1))\n",
        "    plt.show()    \n",
        "\n",
        "# evaluate the discriminator and plot generated images\n",
        "def summarize_performance(epoch, g_model, d_model, dataset, latent_dim, n_samples=2):\n",
        "    # prepare real samples\n",
        "    X_real, y_real = get_real_samples(dataset, n_samples)\n",
        "    # evaluate discriminator on real examples\n",
        "    _, acc_real = d_model.evaluate(X_real, y_real, verbose=0)\n",
        "    # prepare fake examples\n",
        "    x_fake, y_fake = generate_fake_samples(g_model, latent_dim, n_samples)\n",
        "    # evaluate discriminator on fake examples\n",
        "    _, acc_fake = d_model.evaluate(x_fake, y_fake, verbose=0)\n",
        "    # summarize discriminator performance\n",
        "    print('>Accuracy [real: %.0f%%, fake: %.0f%%]' % (acc_real*100, acc_fake*100))\n",
        "    # show plot\n",
        "\n",
        "def generate_and_save_images(model, epoch, test_input):\n",
        "  # Notice `training` is set to False.\n",
        "  # This is so all layers run in inference mode (batchnorm).\n",
        "     \n",
        "    fig=plt.figure(figsize=(10, 10))\n",
        "    plt.imshow( np.reshape((0.5 * generator.predict(np.random.normal(0,1,(1,noise_dim))) + 0.5), (128, 128)), cmap='gray')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jd-3GCUEiKtv"
      },
      "source": [
        "### Generator loss\n",
        "The generator's loss quantifies how well it was able to trick the discriminator. Intuitively, if the generator is performing well, the discriminator will classify the fake images as real (or 1). Here, we will compare the discriminators decisions on the generated images to an array of 1s."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90BIcCKcDMxz"
      },
      "source": [
        "def train(g_model, d_model, gan_model, dataset, latent_dim=100, n_epochs=100, n_batch=128):\n",
        "    bat_per_epo = int(dataset.shape[0] / n_batch)\n",
        "    half_batch = int(n_batch / 2)\n",
        "    # manually enumerate epochs\n",
        "    start = time.time()\n",
        "    for i in range(n_epochs):\n",
        "        display.clear_output(wait=True)\n",
        "      #  try:\n",
        "        if i>0:\n",
        "          print('Epoch: %d,  Loss: D_real = %.3f, D_fake = %.3f,  G = %.3f' %   (i+1, d_loss1, d_loss2, g_loss))\n",
        "          summarize_performance(i, g_model, d_model, dataset, latent_dim)    \n",
        "       # except:\n",
        "        #  print('prep')\n",
        "        generate_and_save_images(g_model,\n",
        "                             i + 1,\n",
        "                             seed)\n",
        "        # enumerate batches over the training set\n",
        "        for j in range(bat_per_epo):\n",
        "            # get randomly selected 'real' samples\n",
        "            X_real, y_real = get_real_samples(dataset, half_batch)\n",
        "            # update discriminator model weights\n",
        "            d_loss1, _ = d_model.train_on_batch(X_real, y_real)\n",
        "            # generate 'fake' examples\n",
        "            X_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
        "            # update discriminator model weights\n",
        "            d_loss2, _ = d_model.train_on_batch(X_fake, y_fake)\n",
        "            # prepare points in latent space as input for the generator\n",
        "            X_gan = generate_latent_points(latent_dim, n_batch)\n",
        "            # create inverted labels for the fake samples\n",
        "            y_gan = np.ones((n_batch, 1))\n",
        "            # update the generator via the discriminator's error\n",
        "            g_loss = gan_model.train_on_batch(X_gan, y_gan)\n",
        "            # summarize loss on this batch\n",
        "  \n",
        "    print ('Total time for training {} epochs is {} sec'.format(n_epochs, (time.time()-start)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgIc7i0th_Iu"
      },
      "source": [
        "The discriminator and the generator optimizers are different since we will train two networks separately."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWCn_PVdEJZ7"
      },
      "source": [
        "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rw1fkAczTQYh"
      },
      "source": [
        "## Define the training loop\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NS2GWywBbAWo"
      },
      "source": [
        "EPOCHS = 10000\n",
        "noise_dim = 100\n",
        "num_examples_to_generate = 16\n",
        "\n",
        "# We will reuse this seed overtime (so it's easier)\n",
        "# to visualize progress in the animated GIF)\n",
        "seed = tf.random.normal([num_examples_to_generate, noise_dim])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jylSonrqSWfi"
      },
      "source": [
        "The training loop begins with generator receiving a random seed as input. That seed is used to produce an image. The discriminator is then used to classify real images (drawn from the training set) and fakes images (produced by the generator). The loss is calculated for each of these models, and the gradients are used to update the generator and discriminator."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2aFF7Hk3XdeW"
      },
      "source": [
        "**Generate and save images**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZrd4CdjR-Fp"
      },
      "source": [
        "## Train the model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        },
        "id": "Ly3UN0SLLY2l",
        "outputId": "9a1f7e72-3d82-4b69-98fd-4fa24e537b41"
      },
      "source": [
        "discriminator = define_discriminator()\n",
        "generator = define_generator(noise_dim)\n",
        "\n",
        "# create the gan\n",
        "gan = define_gan(generator, discriminator)\n",
        "\n",
        "# train model\n",
        "train(generator, discriminator, gan, np_train, noise_dim, EPOCHS, 40)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 213,  Loss: D_real = 0.250, D_fake = 0.256,  G = 0.685\n",
            ">Accuracy [real: 0%, fake: 0%]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}